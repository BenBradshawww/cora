{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.utils import to_networkx, to_dense_adj\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "from plotting.plotting_functions import plot_splits\n",
    "\n",
    "from misc.data_utils_cora import get_splits\n",
    "from misc.lipschitz_constant import estimate_lipschitz_constant\n",
    "\n",
    "from models.locally_linear_embeddings import locally_linear_embedding\n",
    "from models.laplacian_eigenmaps import laplacian_eigemaps\n",
    "from models.grarep import grarep_train\n",
    "from models.deepwalk import DeepWalk\n",
    "from models.logistic_regression import LogisticRegression, train, test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Planetoid('./data/Planetoid', name='Cora')[0]\n",
    "\n",
    "nodes = np.array(range(data.num_nodes))\n",
    "edges = np.array(data.edge_index.T)\n",
    "\n",
    "A = to_dense_adj(edge_index=data.edge_index, max_num_nodes=data.num_nodes)[0]\n",
    "\n",
    "labels = data.y\n",
    "y_one_hot = torch.nn.functional.one_hot(labels)\n",
    "y_one_hot = y_one_hot.float()\n",
    "\n",
    "idx_train, idx_val, idx_test = get_splits(y_one_hot, pct_train=25)\n",
    "\n",
    "num_classes = 7\n",
    "input_shape=128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_splits(labels, idx_train, idx_val, idx_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Locally Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = locally_linear_embedding(A, n_neighbours=5, d=128)\n",
    "torch.save(embeddings, './embeddings/locally_linear_embeddings.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = torch.load('./embeddings/locally_linear_embeddings.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = embeddings.shape[1]\n",
    "num_classes = y_one_hot.shape[1]\n",
    "\n",
    "model = LogisticRegression(input_size, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model hyperparameters\n",
    "lipschitz_constant = estimate_lipschitz_constant(model, embeddings, n_estimates=100000)\n",
    "learning_rate = 1/(lipschitz_constant*1.2)\n",
    "print(f'Learning Rate: {learning_rate}')\n",
    "num_epochs = 20000\n",
    "display_every = 500\n",
    "patience = 100\n",
    "model_path='./model_weights/locally_linear_embedding.pth'\n",
    "output_path='./history/locally_linear_embeddings_loss.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "train(model=model, learning_rate=learning_rate, embeddings=embeddings, labels=labels, idx_train=idx_train, idx_val=idx_val, display_every=display_every, num_epochs=num_epochs, model_path=model_path, output_path=output_path)\n",
    "\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "\n",
    "# Testing\n",
    "test(model=model, embeddings=embeddings, labels=labels, idx_test=idx_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laplacian Eigenmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = laplacian_eigemaps(A, d=128, verbose=0)\n",
    "torch.save(embeddings, './embeddings/laplacian_eigenmap_embeddings.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = torch.load('./embeddings/laplacian_eigenmap_embeddings.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = embeddings.shape[1]\n",
    "num_classes = y_one_hot.shape[1]\n",
    "\n",
    "model = LogisticRegression(input_size, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model hyperparameters\n",
    "lipschitz_constant = estimate_lipschitz_constant(model, embeddings, n_estimates=10000)\n",
    "learning_rate = 1/(lipschitz_constant*1.2)\n",
    "print(f'Learning Rate: {learning_rate}')\n",
    "num_epochs = 20000\n",
    "display_every = 100\n",
    "patience = 20\n",
    "model_path='./model_weights/laplacian_eigenmaps.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "train(model=model, learning_rate=learning_rate, embeddings=embeddings, labels=labels, idx_train=idx_train, idx_val=idx_val, num_epochs=num_epochs, model_path=model_path, output_path='./history/laplacian_eigenmaps_loss.csv')\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "\n",
    "# Testing\n",
    "test(model=model, embeddings=embeddings, labels=labels, idx_test=idx_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GraRep Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings=grarep_train(A, K=4, emb_size_per_K=32)\n",
    "torch.save(embeddings, './embeddings/grarep_embedding.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = torch.load('./embeddings/grarep_embedding.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = embeddings.shape[1]\n",
    "num_classes = y_one_hot.shape[1]\n",
    "\n",
    "model = LogisticRegression(input_size, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model hyperparameters\n",
    "lipschitz_constant = estimate_lipschitz_constant(model, embeddings, n_estimates=20000)\n",
    "learning_rate = 1/(lipschitz_constant*1.2)\n",
    "print(f'Learning Rate: {learning_rate}')\n",
    "num_epochs = 20000\n",
    "display_every = 10\n",
    "patience = 20\n",
    "model_path='./model_weights/grarep.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "train(model=model, learning_rate=learning_rate, embeddings=embeddings, labels=labels, idx_train=idx_train, idx_val=idx_val, num_epochs=num_epochs, display_every=display_every, patience=patience, model_path=model_path, output_path='./history/grarep_loss.csv')\n",
    "\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "\n",
    "# Testing\n",
    "test(model=model, embeddings=embeddings, labels=labels, idx_test=idx_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepWalk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.from_numpy_array(A.numpy())\n",
    "deepwalk = DeepWalk(G, num_walks=10, length_walk=5, window_size=3, embedding_size=128)\n",
    "model = deepwalk.train()\n",
    "embeddings = torch.torch.FloatTensor([model.wv[str(node)] for node in G.nodes()])\n",
    "torch.save(embeddings, './embeddings/deepwalk_embedding.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = torch.load('./embeddings/deepwalk_embedding.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = embeddings.shape[1]\n",
    "num_classes = y_one_hot.shape[1]\n",
    "\n",
    "model = LogisticRegression(input_size, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model hyperparameters\n",
    "lipschitz_constant = estimate_lipschitz_constant(model, embeddings, n_estimates=20000)\n",
    "learning_rate = 1/(lipschitz_constant*1.2)\n",
    "print(f'Learning Rate: {learning_rate}')\n",
    "num_epochs = 20000\n",
    "display_every = 10\n",
    "patience = 20\n",
    "model_path='./model_weights/deepwalk.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "train(model=model, learning_rate=learning_rate, embeddings=embeddings, labels=labels, idx_train=idx_train, idx_val=idx_val, num_epochs=num_epochs, display_every=display_every, patience=patience, model_path=model_path, output_path='./history/deepwalk_loss.csv')\n",
    "\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "\n",
    "# Testing\n",
    "test(model=model, embeddings=embeddings, labels=labels, idx_test=idx_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def get_data(path):\n",
    "\n",
    "\tdf = pd.read_csv(path)\n",
    "\n",
    "\ttrain_loss = df['loss_train'].to_list()\n",
    "\tval_loss = df['loss_val'].to_list()\n",
    "\n",
    "\treturn train_loss, val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "locally_linear_embeddings_train_loss,  locally_linear_embeddings_val_loss =  get_data('./history/locally_linear_embeddings_loss.csv')\n",
    "laplacian_eigemaps_train_loss,  laplacian_eigemaps_val_loss =  get_data('./history/laplacian_eigenmaps_loss.csv')\n",
    "grarep_train_loss,  grarep_val_loss =  get_data('./history/grarep_loss.csv')\n",
    "deepwalk_train_loss, deepwalk_val_loss =  get_data('./history/deepwalk_loss.csv')\n",
    "\n",
    "x = list(range(1, len(locally_linear_embeddings_train_loss)+1))\n",
    "\n",
    "trace1 = go.Scatter(x=x, y=locally_linear_embeddings_train_loss, mode='lines', name='Locally Linear Embeddings Train Loss')\n",
    "trace2 = go.Scatter(x=x, y=laplacian_eigemaps_train_loss, mode='lines', name='Laplacian Eigenmaps Train Loss')\n",
    "trace3 = go.Scatter(x=x, y=grarep_train_loss, mode='lines', name='Grarep Train Loss')\n",
    "trace4 = go.Scatter(x=x, y=deepwalk_train_loss, mode='lines', name='Deepwalk Train Loss')\n",
    "\n",
    "trace5 = go.Scatter(x=x, y=locally_linear_embeddings_val_loss, mode='lines', name='Locally Linear Embeddings Val Loss', line=dict(dash='dash', color='#636EFA'))\n",
    "trace6 = go.Scatter(x=x, y=laplacian_eigemaps_val_loss, mode='lines', name='Laplacian Eigenmaps Val Loss', line=dict(dash='dash', color='#EF553B'))\n",
    "trace7 = go.Scatter(x=x, y=grarep_val_loss, mode='lines', name='Grarep Val Loss', line=dict(dash='dash', color='#00CC96'))\n",
    "trace8 = go.Scatter(x=x, y=deepwalk_val_loss, mode='lines', name='Deepwalk Val Loss', line=dict(dash='dash', color='#AB63FA'))\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(trace1)\n",
    "fig.add_trace(trace2)\n",
    "fig.add_trace(trace3)\n",
    "fig.add_trace(trace4)\n",
    "fig.add_trace(trace5)\n",
    "fig.add_trace(trace6)\n",
    "fig.add_trace(trace7)\n",
    "fig.add_trace(trace8)\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Shallow Embedding Methods Loss\",\n",
    "    xaxis_title=\"Epoch\",\n",
    "    yaxis_title=\"Loss\",\n",
    "    legend_title=\"Loss\",\n",
    "    template=\"plotly\"\n",
    ")\n",
    "\n",
    "fig.update_xaxes(range=[0, 100])\n",
    "fig.update_yaxes(range=[0.4, 2])\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
